{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbht04/ai-agents/blob/main/autonomous_it_support_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment: The Autonomous IT Support Agent**\n",
        "\n",
        "This is a coding assignment for the **Level 1 IT Incident Responder**.\n",
        "\n",
        "This assignment assumes the learners have the `openai` library installed and an API key ready and stored in the variable name `OPENAI_APIKEY` as a notebook secret variable and enabled\n",
        "\n",
        "---\n",
        "\n",
        "**Objective:** You are building an AI agent that acts as the \"first responder\" for server incidents. It must:\n",
        "\n",
        "1. **Investigate:** Check server health and logs when a user reports an issue.\n",
        "2. **Act:** If CPU is critical (>90%), it should **Restart** the service.\n",
        "3. **Escalate:** If the issue is complex or logs show a major problem it should **Escalate** to a human.\n",
        "\n",
        "**Your Task:** complete the code below by filling in the sections marked `### TODO`."
      ],
      "metadata": {
        "id": "VIBIrNJ0DjVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "_2sMjKhmD1OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_APIKEY = userdata.get('OPENAI_APIKEY')\n",
        "client = OpenAI(api_key=OPENAI_APIKEY)\n",
        "\n",
        "# Optional: Verify it loaded (printing secrets is usually discouraged in production)\n",
        "print(\"API Key loaded successfully.\")"
      ],
      "metadata": {
        "id": "249KM3HSD2K0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45183c0-b29a-497e-f1d7-1e1c364c03b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Client\n",
        "\n",
        "==========================================\n",
        "## PART 1: DEFINE THE TOOLS (BUSINESS LOGIC)\n",
        "=========================================="
      ],
      "metadata": {
        "id": "AUSoP6RJEGhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Already implement tool 1: Check Health ---\n",
        "def get_server_health(server_id: str) -> str:\n",
        "    \"\"\"Returns CPU and Memory usage for a given server.\"\"\"\n",
        "    print(f\"-> TOOL: Checking health for {server_id}...\")\n",
        "\n",
        "    metrics = {\n",
        "        # Scenario 1: High CPU (Needs Restart)\n",
        "        \"payment-server-01\": {\"cpu\": \"98%\", \"memory\": \"40%\", \"status\": \"Warning\"},\n",
        "\n",
        "        # Scenario 2: Healthy (No Action Needed)\n",
        "        \"db-node-02\": {\"cpu\": \"12%\", \"memory\": \"60%\", \"status\": \"Healthy\"},\n",
        "\n",
        "        # Scenario 3: High Memory Leak (Needs Restart or Escalation)\n",
        "        \"auth-service-03\": {\"cpu\": \"45%\", \"memory\": \"95%\", \"status\": \"Critical\"},\n",
        "\n",
        "        # Scenario 4: Network/Dependency Failure (Needs Escalation)\n",
        "        \"search-index-09\": {\"cpu\": \"10%\", \"memory\": \"15%\", \"status\": \"Error\"},\n",
        "\n",
        "        # Scenario 5: Completely Normal\n",
        "        \"frontend-node-04\": {\"cpu\": \"25%\", \"memory\": \"30%\", \"status\": \"Healthy\"},\n",
        "    }\n",
        "\n",
        "    result = metrics.get(server_id, {\"error\": \"Server not found. Check the ID.\"})\n",
        "    return json.dumps(result)\n"
      ],
      "metadata": {
        "id": "7VFFpty7ERw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_recent_logs(server_id: str, lines: int = 5) -> str:\n",
        "    \"\"\"Returns the last N lines of logs.\"\"\"\n",
        "    print(f\"-> TOOL: Fetching last {lines} log lines for {server_id}...\")\n",
        "\n",
        "    # Different logs for different servers to trigger different agent behaviors\n",
        "    log_database = {\n",
        "        \"payment-server-01\": [\n",
        "            \"[INFO] Request received /pay/v1\",\n",
        "            \"[WARN] CPU threshold exceeded 90%\",\n",
        "            \"[WARN] Thread pool exhaustion\",\n",
        "            \"[CRITICAL] Process hung, not accepting new connections\",\n",
        "            \"[ERROR] Timeout waiting for thread\"\n",
        "        ],\n",
        "        \"db-node-02\": [\n",
        "            \"[INFO] Backup started\",\n",
        "            \"[INFO] Backup completed successfully\",\n",
        "            \"[INFO] User query executed in 12ms\",\n",
        "            \"[INFO] Health check: OK\",\n",
        "            \"[INFO] Replication sync active\"\n",
        "        ],\n",
        "        \"auth-service-03\": [\n",
        "            \"[INFO] Token validated user_882\",\n",
        "            \"[WARN] Garbage collection taking too long (>5s)\",\n",
        "            \"[ERROR] java.lang.OutOfMemoryError: Java heap space\",\n",
        "            \"[CRITICAL] Application crashing due to memory leak\",\n",
        "            \"[INFO] Restarting context...\"\n",
        "        ],\n",
        "        \"search-index-09\": [\n",
        "            \"[INFO] Indexing started\",\n",
        "            \"[ERROR] Connection refused: elastic-cluster-main:9200\",\n",
        "            \"[ERROR] Failed to write document ID 4432\",\n",
        "            \"[CRITICAL] Dependency Unreachable: Search Engine is down\",\n",
        "            \"[ERROR] Retrying in 30s...\"\n",
        "        ],\n",
        "        \"frontend-node-04\": [\n",
        "            \"[INFO] GET /home 200 OK\",\n",
        "            \"[INFO] GET /assets/logo.png 200 OK\",\n",
        "            \"[INFO] GET /login 200 OK\",\n",
        "            \"[INFO] GET /api/v1/status 200 OK\",\n",
        "            \"[INFO] Health check passed\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Default logs if server not found in specific list\n",
        "    default_logs = [\"[INFO] System stable\", \"[INFO] Heartbeat signal received\"]\n",
        "\n",
        "    logs = log_database.get(server_id, default_logs)\n",
        "    return json.dumps({\"logs\": logs[:lines]})"
      ],
      "metadata": {
        "id": "bPGJ20WcEc7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ----- Implement code below -----\n",
        "---\n"
      ],
      "metadata": {
        "id": "ZQMfqNI1EjXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK 1: Implement the Restart Tool ---\n",
        "def restart_service(server_id: str) -> str:\n",
        "\n",
        "    print(\"-> TOOL: Restarting service...\")\n",
        "\n",
        "    # --- Error Case 1: Missing or empty server_id ---\n",
        "    if not server_id or not isinstance(server_id, str):\n",
        "        return json.dumps({\n",
        "            \"status\": \"error\",\n",
        "            \"message\": \"Invalid server_id provided\"\n",
        "        })\n",
        "\n",
        "    # --- Error Case 2: Simulated failure scenario ---\n",
        "\n",
        "    if server_id.lower() == \"unreachable\":\n",
        "        return json.dumps({\n",
        "            \"status\": \"error\",\n",
        "            \"message\": f\"Server '{server_id}' is unreachable. Restart failed.\"\n",
        "        })\n",
        "\n",
        "    # --- Success Case ---\n",
        "    return json.dumps({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": f\"Server '{server_id}' restarted successfully\"\n",
        "    })\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jlcr6af-E1cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TASK 2: Implement the Escalation Tool ---\n",
        "def escalate_to_engineer(summary: str) -> str:\n",
        "\n",
        "\n",
        "    print(\"-> TOOL: Escalating to human...\")\n",
        "\n",
        "    # --- Error Case 1: Missing or invalid summary ---\n",
        "    if not summary or not isinstance(summary, str):\n",
        "        return json.dumps({\n",
        "            \"status\": \"error\",\n",
        "            \"message\": \"Invalid summary provided\"\n",
        "        })\n",
        "\n",
        "    # --- Success Case ---\n",
        "    return json.dumps({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Escalation ticket created successfully\",\n",
        "        \"summary\": summary\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "s0FrD0kpE6U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map functions for the agent execution loop\n",
        "AVAILABLE_FUNCTIONS = {\n",
        "    \"get_server_health\": get_server_health,\n",
        "    \"fetch_recent_logs\": fetch_recent_logs,\n",
        "    \"restart_service\": restart_service,\n",
        "    \"escalate_to_engineer\": escalate_to_engineer,\n",
        "}"
      ],
      "metadata": {
        "id": "IPiZltMuFH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "==========================================\n",
        "## PART 2: DEFINE THE AGENT SCHEMA\n",
        "==========================================\n"
      ],
      "metadata": {
        "id": "kczZLKZSFKwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools_schema = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_server_health\",\n",
        "            \"description\": \"Checks the current CPU and memory usage of a specific server.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"server_id\": {\"type\": \"string\", \"description\": \"The ID of the server, e.g., 'payment-server-01'\"}\n",
        "                },\n",
        "                \"required\": [\"server_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"fetch_recent_logs\",\n",
        "            \"description\": \"Retrieves the most recent log entries from a server to diagnose errors.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"server_id\": {\"type\": \"string\", \"description\": \"The ID of the server.\"},\n",
        "                    \"lines\": {\"type\": \"integer\", \"description\": \"Number of log lines to fetch.\"}\n",
        "                },\n",
        "                \"required\": [\"server_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    # --- >>>> TASK 3: Define Schema for restart_service ---\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"restart_service\",\n",
        "            \"description\": \"Restarts the service for a particular Server\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"server_id\": {\"type\": \"string\", \"description\": \"The ID of the server, e.g., 'payment-server-01'\"}\n",
        "                },\n",
        "                \"required\": [\"server_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    # --- >>>> TASK 4: Define Schema for escalate_to_engineer ---\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"escalate_to_engineer\",\n",
        "            \"description\": \"Escalates the issue to a human engineer when automated fixes fail or the error is unknown.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                   \"summary\": {\"type\": \"string\", \"description\": \"summary of the error'\"}\n",
        "                },\n",
        "                \"required\": [\"summary\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pDGPzSUvDjVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ==========================================\n",
        "## PART 3: THE AGENT EXECUTION LOOP\n",
        " ==========================================\n"
      ],
      "metadata": {
        "id": "GjogRxBWFw7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_it_agent(user_issue: str):\n",
        "    print(f\"\\n--- New Incident: {user_issue} ---\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a Level 1 IT Responder. Investigate server issues. \"\n",
        "                                      \"If CPU or Memory is > 90%, restart the service. If logs show critical dependency errors (like connection refused) that a restart won't fix, escalate to an engineer.\"},\n",
        "        {\"role\": \"user\", \"content\": user_issue}\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n[AI Thinking...]\")\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools_schema,\n",
        "            tool_choice=\"auto\"\n",
        "        )\n",
        "\n",
        "        response_msg = response.choices[0].message\n",
        "        messages.append(response_msg)\n",
        "\n",
        "        if response_msg.tool_calls:\n",
        "            for tool_call in response_msg.tool_calls:\n",
        "                func_name = tool_call.function.name\n",
        "                func_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                # Retrieve the actual python function based on name\n",
        "                function_to_call = AVAILABLE_FUNCTIONS.get(func_name)\n",
        "\n",
        "                if function_to_call:\n",
        "                    # Execute the function\n",
        "                    tool_output = function_to_call(**func_args)\n",
        "\n",
        "                    # Append tool result back to the conversation\n",
        "                    messages.append({\n",
        "                        \"role\": \"tool\",\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"name\": func_name,\n",
        "                        \"content\": tool_output\n",
        "                    })\n",
        "\n",
        "        else:\n",
        "            print(f\"\\n[FINAL RESPONSE]: {response_msg.content}\")\n",
        "            break"
      ],
      "metadata": {
        "id": "_6kfO1sJFdKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ==========================================\n",
        "## PART 4: TEST SCENARIOS\n",
        " ==========================================\n"
      ],
      "metadata": {
        "id": "ySm6klUTFn0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario A: Should trigger a restart (CPU is 98%)\n",
        "run_it_agent(\"The payment-server-01 is extremely slow and timing out.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5zAvAOP_CTD",
        "outputId": "9c40992d-7e6a-4310-bf30-24b93edc2706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Incident: The payment-server-01 is extremely slow and timing out. ---\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Checking health for payment-server-01...\n",
            "-> TOOL: Fetching last 10 log lines for payment-server-01...\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Restarting service...\n",
            "\n",
            "[AI Thinking...]\n",
            "\n",
            "[FINAL RESPONSE]: The service on `payment-server-01` was consuming 98% CPU, which likely caused the slowness and timeouts. I have restarted the service, and it was successful. The server should be operating normally again. Please let me know if there are any further issues!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario B: Should trigger an escalation (DB is healthy but logs might be weird)\n",
        "run_it_agent(\"Something is wrong with db-node-02\")"
      ],
      "metadata": {
        "id": "iMIwpX6YFqy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc803e7-9293-4d1c-aefa-ecd83382163a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Incident: Something is wrong with db-node-02 ---\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Checking health for db-node-02...\n",
            "-> TOOL: Fetching last 50 log lines for db-node-02...\n",
            "\n",
            "[AI Thinking...]\n",
            "\n",
            "[FINAL RESPONSE]: The server \"db-node-02\" appears to be functioning normally based on the health check with CPU usage at 12% and memory usage at 60%. The status is marked as \"Healthy\".\n",
            "\n",
            "The recent logs show normal operations such as backup processes and health checks, with no critical errors reported. If there are specific issues you are experiencing with \"db-node-02,\" please provide more details so I can assist you further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdce78bb",
        "outputId": "a892dbc8-c7bb-4194-a922-d8dbe5e48aee"
      },
      "source": [
        "# Custom Python Script to fetch the list of models from OpenAI\n",
        "try:\n",
        "    # Fetch the list of models from OpenAI\n",
        "    models = client.models.list()\n",
        "\n",
        "    # Extract the IDs and sort them alphabetically\n",
        "    model_ids = sorted([model.id for m in models for model in [m]])\n",
        "\n",
        "    print(f\"Found {len(model_ids)} available models:\\n\")\n",
        "    for model_id in model_ids:\n",
        "        print(f\"- {model_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching models: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 available models:\n",
            "\n",
            "- gpt-4o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario C: The High Memory Case (auth-service-03)\n",
        "# Agent should see Memory 95% + OutOfMemoryError logs -> Restart\n",
        "run_it_agent(\"Users are reporting login failures on auth-service-03.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "TqWLJ6NfMrYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc93dd26-833e-428c-d95c-aee704070ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Incident: Users are reporting login failures on auth-service-03. ---\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Checking health for auth-service-03...\n",
            "-> TOOL: Fetching last 10 log lines for auth-service-03...\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Restarting service...\n",
            "\n",
            "[AI Thinking...]\n",
            "\n",
            "[FINAL RESPONSE]: The auth-service-03 server experienced a critical memory issue, specifically a memory leak that caused the application to crash. I've restarted the service, and the server has been successfully restarted. Please ask users to try logging in again. If the problem persists, let me know so we can escalate it to an engineer for further investigation.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario D: The Dependency Failure (search-index-09)\n",
        "# Agent should see healthy CPU but \"Connection Refused\" logs -> Escalate\n",
        "run_it_agent(\"Search isn't working. Can you check search-index-09?\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "sCTlVX0HMuvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cbfde5-a557-4c78-8651-f852c23ecdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Incident: Search isn't working. Can you check search-index-09? ---\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Checking health for search-index-09...\n",
            "-> TOOL: Fetching last 10 log lines for search-index-09...\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Escalating to human...\n",
            "\n",
            "[AI Thinking...]\n",
            "\n",
            "[FINAL RESPONSE]: I've reviewed the issue with `search-index-09`. The server's CPU and memory usage are normal, but the logs indicate a critical dependency error: \"Connection refused\" to the main search engine cluster at `elastic-cluster-main:9200`. This issue has been escalated to an engineer for further investigation, and an escalation ticket has been successfully created.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scenario E: The Healthy Server (frontend-node-04)\n",
        "# Agent should see normal stats and 200 OK logs -> Do nothing / Report healthy\n",
        "run_it_agent(\"Check frontend-node-04 just to be safe.\")"
      ],
      "metadata": {
        "id": "6ATtadhxMx90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6277083-3d7a-4daa-862d-fe08be3dfbc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Incident: Check frontend-node-04 just to be safe. ---\n",
            "\n",
            "[AI Thinking...]\n",
            "-> TOOL: Checking health for frontend-node-04...\n",
            "\n",
            "[AI Thinking...]\n",
            "\n",
            "[FINAL RESPONSE]: The server \"frontend-node-04\" is currently healthy with CPU usage at 25% and memory usage at 30%. There are no immediate concerns to address.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}